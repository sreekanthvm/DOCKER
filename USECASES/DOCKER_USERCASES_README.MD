# DOCKER USE CASES

* **Portability** : Easily transfer and publish the same changes in all development machines irrespective of which team member makes a new addition or a change.
* **Reusability**: Reuse components created in one machine on another n number of times as per requirements for two or more different pusposes by forking them as desired.
* **Computing environment isolation**: Regardless of the platform the application is deployed, everything, including the code, dependecies, and more, will stay consistent. Improvee productivity considerably!
* **Mobility**: Docker is compatible with most user parent platforms like Linux, macOS, and Windows. It can run anywhere, provided there is one targeted OS.
* **Testing** : Docker-based result files are images. These images are versioned and can easily be rolled back for any iteration. This methodology supports Continuous Integrations (CI) an Continuous Deployment (CD) parctices for continuous testing at any given time.
* **Scaling**: Without any massive architecture overhaul, app with small processes can be build inclusive of internal API collabarations at scale. In simple words, you can create apps with room for scaling as per your desire.


# App Infrastructure isolation
* If you are a business already practicing DevOps or into software evolution, you might be aware of the issues that arise in the name of **dependency** hell. When you install a software package created on one machine on another, there are issues that the DevOps team may face in running apps with specific versions, libraries, dependencies, and so much more.
* With the help of Docker, you can run multiple apps or the same app on different machines without letting something as versions or other such factors affect the development process. This is made possible as Docker uses the kernel of a host system and yet runs like an isolation application, unlike VMs. This helps build apps where infrastructure can be isolated form the computing environment requirements during development. It also reduces a considerable amount of hassle and confusion in DevOps collabaration between teams.
# Multi-tenancy support
* When building an application that requires multi-tenancy, the development process may get complicated given the numerous dependencies and independent functions involved. Managing the development operations may become challenging to handle. Moreover, rearchitecting the app may also be required in some cases, which is a headache and time-consuming. Not to mention the cost your business would have to incur.

* With the help of Docker, you can quickly isolate different computing environments, as mentioned a couple of times in this article. Development teams will have the power to run multiple instances of the application tiers on different tenants, respectively. The increased speed of Docker to spin up operations also serves as an easy way to view or manage the containers provisioned on any system.
# Improvement in software testing
* Application development involves testing, a necessary process that cannot be simply ignored. The amount of effort and procedures that go into the types of testing conducted and test cases created for every development and deployment process is tedious. Multiply the headache when the test has to be conducted on different machines. What if you can run all your tests automatically? Moreover, what if you can simultaneously isolate your development tests from deployment tests?

* Dockers help your business to accomplish just that. It reduces the number of attempts required to rerun tests. If tests fail on the clients’ end, they will also fail on the local machine. In other words, test results will be the same in all computing environments.
# Smart Disaster Recovery (DR)
* Committing the development pipeline to one OS or a couple of assigned machines is always an excellent plan to keep discrepancies under control. Yet, not all challenges can be foreseen. What if the data, transferred to a new machine, is corrupted? Though Docker can handle dependency issues, can it manage such data storage corruptions?

* The answer is yes. With the help of Docker use cases, you can instantly create and destruct container tasks as you please. Furthermore, Docker provides possibilities to commit your data within the container platform before the image file is transferred to another machine. This way, even if something goes wrong, you can use the Docker images to restore your data. Moreover, if your business is already using the cloud or considering migrating towards the cloud, you can set up a DR plan on the cloud zone at ease.

# Continuous rapid deployment
* Gone are the days when deployment began only after development processes were complete. DevOps and Docker together manage to reduce deployment to seconds. Before Docker, applications built had to be run on the parent server and environment before making it live on any other environment. Not to mention the configuration management and maintenance of consistency in versions that increase the deployment time.

* With Docker, you can easily run the app on any server environment, and evidently, it also provides version-controlled container images. Furthermore, stage environments can be set up via the Docker engine, which enables CD abilities.
# Creation of microservices architecture
* Organizations, be it small or large, are actively adopting microservices replacing monolithic apps for various reasons such as scalability, performance, etc. However, it is fundamental to be aware of the issue that microservice architecture may pose regarding dependencies since architecture is broken down into individual and smaller components.

* Containerization with Docker provides the ability to isolate these individual components into different workload environments. Thus, teams can independently work on their assigned components and yet deploy and scale them simultaneously by collaborating with other component-related teams. Specifically, Docker Hub and Docker Desktop focus on running microservice-based applications if you are interested.

# Simplification of code configuration
* The most significant advantage of a VM is its ability to run on any given platform with its own configuration on top of the infrastructure your app follows. While Docker seems to fulfill the same, it avoids the overhead you may incur using a VM. Unlike a virtual machine, with Docker, you can create your own configuration and set it up on a supporting computing environment that you created.

* In addition to that, you can accomplish all this in the form of simple code and deploy it as per the requirement. Imagine the possibilities you can obtain from such a use case. You could also describe this as the decoupling of infrastructure according to the application environment. With any extra hardware or complicated coding, obtain the freedom to run your app across any PaaS or IaaS.

# Management of development pipeline
* As stated above, Docker supports different computing environments. Given that, when developed codes are transferred between different systems to production, there would be many environments it passes through. The code would be influenced by minor changes or differences at each development phase in each environment. For instance, without Docker, the modifications incurred along the way could be irreparable, resulting in inconsistent codes and infrastructure.

* However, with Docker, the development and deployment pipeline can strictly maintain consistency in coding, infrastructure creation, and even in the usage of resources. Furthermore, Docker’s resulting image file helps achieve a zero-change state in the written code even when it passes across countless development environments and production phases.
#  Increased developer productivity
* Any good software project will focus on writing codes that are close to production as much as possible and create development environments that are fast and interactive. With the help of Docker, a development environment can be built with low memory capacity without adding an unnecessary memory footprint to the memory that the host repository already holds. A dozen services can run at low memory with Docker.

* Since Docker also supports sharing data volumes, it helps make the application code available on any host OS container even if the environment is running on a VM. Furthermore, given that the same VM is present in all development systems, the data volumes, despite being stored in different folders, can be synced across all systems since it all runs on a host OS. All this proves to be a beneficial aspect for improving the productivity of development teams.


For more info(https://www.simform.com/blog/docker-use-cases/) (https://blog.oursky.com/2019/07/03/docker-use-cases/)